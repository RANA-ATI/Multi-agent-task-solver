{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d18ad15e",
   "metadata": {},
   "source": [
    "# **Basic Multi Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49deb153",
   "metadata": {},
   "source": [
    "### **``Import the required packages``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1401032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import equired packages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa370c70",
   "metadata": {},
   "source": [
    "### **``Define a state schema.``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff4b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use a schema of type TypedDict. Create a class called MyGraphState with two variables. count of datatype int and msg of datatype str.\n",
    "\n",
    "# Create the structure of the schema for the graph.\n",
    "class MyGraphState(TypedDict):\n",
    "  count: int\n",
    "  msg: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ac4765",
   "metadata": {},
   "source": [
    "### **``Define nodes``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96ceff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will define a function that will be used in multiple nodes in this graph.\n",
    "\n",
    "# Define your node\n",
    "def counter(state: MyGraphState):\n",
    "  state[\"count\"] += 1\n",
    "  state[\"msg\"] = f\"Counter function has been called {state['count']} time(s)\"\n",
    "  return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fec8c5",
   "metadata": {},
   "source": [
    "### **``Create a graph instance of StateGraph``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9271d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of StateGraph with the structure of MyGraphState\n",
    "workflow = StateGraph(MyGraphState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0472a9d8",
   "metadata": {},
   "source": [
    "### **``Add nodes to Graph``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b13b7194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x20bf3acf620>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add three nodes to the workflow which are replicas of \"counter\"\n",
    "workflow.add_node(\"Node1\", counter)\n",
    "workflow.add_node(\"Node2\", counter)\n",
    "workflow.add_node(\"Node3\", counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2879e41d",
   "metadata": {},
   "source": [
    "### **``Add edges to the graph``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d5d39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x20bf3acf620>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the nodes one after another. \n",
    "# All the Nodes in the workflow take state as input, update the state and pass it to the next Node as input.\n",
    "# Output of Node1 goes to Node2 as input. Output of Node2 goes to Node3 as input.\n",
    "workflow.add_edge(START, \"Node1\")\n",
    "workflow.add_edge(\"Node1\", \"Node2\")\n",
    "workflow.add_edge(\"Node2\", \"Node3\")\n",
    "\n",
    "workflow.add_edge(\"Node3\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28523dfc",
   "metadata": {},
   "source": [
    "### **``Compile the graph``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3804009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the workflow\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6269e716",
   "metadata": {},
   "source": [
    "### **``Visualize the graph``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2affd7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize your graph\n",
    "from IPython.display import Image, display\n",
    "png = app.get_graph().draw_mermaid_png()\n",
    "\n",
    "display(Image(png))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f38114",
   "metadata": {},
   "source": [
    "### **``Test your graph``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7133c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count': 3, 'msg': 'Counter function has been called 3 time(s)'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"count\": 0, \"msg\":\"hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6390402e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a48f5f5",
   "metadata": {},
   "source": [
    "# **Wand AI Multi Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5351f5e",
   "metadata": {},
   "source": [
    "### **``Import the required packages``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9cf6355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import equired packages\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import pandas as pd\n",
    "from uuid import uuid4\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Annotated, Optional\n",
    "from langchain_core.tools import tool\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_tavily import TavilySearch\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, AIMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce69091",
   "metadata": {},
   "source": [
    "### **``Environment variables setup``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"\"\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9961fc94",
   "metadata": {},
   "source": [
    "### **``LLM setup``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae11cd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add temperature/other kwargs if you like.\n",
    "# llm = init_chat_model(\"google_genai:gemini-2.5-flash\")\n",
    "\n",
    "llm = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020ae52e",
   "metadata": {},
   "source": [
    "### **``Define a state schema.``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a5fdb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGraphState(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "\n",
    "    ## “a list of anything” (effectively list[Any]). Type checkers can’t help you much, and IDE autocomplete is weaker.\n",
    "    # messages: Annotated[list, add_messages]\n",
    "\n",
    "    ## “A list of LangChain message objects” (e.g., HumanMessage, AIMessage, SystemMessage, ToolMessage, …). This matches what LangGraph/ToolNode actually pass around, including .tool_calls on AIMessage.\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "    # Mode controls how far the pipeline runs: \"research\", \"summary\", \"visualize\", \"full\"\n",
    "    mode: str\n",
    "\n",
    "    # If user supplied a table as raw text for visualization\n",
    "    table_text: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994d8f23",
   "metadata": {},
   "source": [
    "### **```Tools```**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5be784",
   "metadata": {},
   "source": [
    "##### **```Tools # 1: Web Search```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "10b1badd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def web_search(user_input: str) -> str:\n",
    "    \"\"\"\n",
    "    Return stitched text result from Tavily (string).\n",
    "    \"\"\"\n",
    "    ts = TavilySearch(max_results=2)\n",
    "    resp = ts.invoke({\"query\": user_input})\n",
    "    chunks = [r.get(\"content\") for r in resp.get(\"results\", []) if r.get(\"content\")]\n",
    "    return \"\\n\\n\".join(chunks) or \"No results found.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33e2916",
   "metadata": {},
   "source": [
    "##### **```Tools # 2: Plot Visualization```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "204924e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def plot_table(table_text: str, chart_type: str = \"line\") -> str:\n",
    "    \"\"\"\n",
    "    Parse table_text into a DataFrame, plot it, save PNG, and return file path.\n",
    "    Accepts CSV or markdown-style table or whitespace-separated table.\n",
    "    \"\"\"\n",
    "\n",
    "    txt = (table_text or \"\").strip()\n",
    "    if not txt:\n",
    "        raise ValueError(\"plot_table: table_text is empty\")\n",
    "\n",
    "    df = None\n",
    "    # 1) markdown pipe table\n",
    "    try:\n",
    "        if '|' in txt and re.search(r'\\|[-\\s:]+\\|', txt):\n",
    "            # remove separator line and outer pipes, keep header + rows\n",
    "            lines = []\n",
    "            for line in txt.splitlines():\n",
    "                if re.match(r'^\\s*\\|?\\s*-{2,}\\s*\\|?', line):\n",
    "                    continue\n",
    "                lines.append(line.strip().strip('|'))\n",
    "            csv_txt = \"\\n\".join(lines)\n",
    "            df = pd.read_csv(io.StringIO(csv_txt))\n",
    "        # 2) plain CSV\n",
    "        elif '\\n' in txt and ',' in txt:\n",
    "            df = pd.read_csv(io.StringIO(txt))\n",
    "    except Exception:\n",
    "        df = None\n",
    "\n",
    "    # 3) whitespace separated\n",
    "    if df is None:\n",
    "        try:\n",
    "            df = pd.read_csv(io.StringIO(txt), sep=r'\\s+')\n",
    "        except Exception:\n",
    "            df = None\n",
    "\n",
    "    if df is None:\n",
    "        raise ValueError(\"plot_table: Unable to parse table_text into a DataFrame. Provide CSV or markdown table with header row.\")\n",
    "\n",
    "    # Choose x and y\n",
    "    x_col = None\n",
    "    for c in df.columns:\n",
    "        if c.lower() in (\"date\", \"year\", \"time\") or re.search(r'date|year|time', c.lower()):\n",
    "            x_col = c\n",
    "            break\n",
    "    if x_col is None:\n",
    "        x_col = df.columns[0]\n",
    "\n",
    "    numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c]) and c != x_col]\n",
    "    y_col = numeric_cols[0] if numeric_cols else (df.columns[1] if len(df.columns) > 1 else None)\n",
    "    if y_col is None:\n",
    "        # try convert second column to numeric\n",
    "        if len(df.columns) >= 2:\n",
    "            try:\n",
    "                df[df.columns[1]] = pd.to_numeric(df[df.columns[1]], errors='coerce')\n",
    "                y_col = df.columns[1]\n",
    "            except Exception:\n",
    "                y_col = None\n",
    "\n",
    "    if y_col is None:\n",
    "        raise ValueError(\"plot_table: No numeric column found to plot. Provide at least one numeric column.\")\n",
    "\n",
    "    # attempt date parse for x\n",
    "    try:\n",
    "        df[x_col] = pd.to_datetime(df[x_col], errors='ignore')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 4.5))\n",
    "    if chart_type == \"line\":\n",
    "        plt.plot(df[x_col], df[y_col], marker='o')\n",
    "    elif chart_type == \"bar\":\n",
    "        plt.bar(df[x_col].astype(str), df[y_col])\n",
    "    elif chart_type == \"scatter\":\n",
    "        plt.scatter(df[x_col], df[y_col])\n",
    "    else:\n",
    "        raise ValueError(f\"plot_table: Unsupported chart_type: {chart_type}\")\n",
    "\n",
    "    plt.title(f\"{y_col} vs {x_col}\")\n",
    "    plt.xlabel(str(x_col))\n",
    "    plt.ylabel(str(y_col))\n",
    "    plt.tight_layout()\n",
    "\n",
    "    out_dir = \"/mnt/data\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    fname = f\"plot_{datetime.utcnow().strftime('%Y%m%d%H%M%S')}_{uuid4().hex[:6]}.png\"\n",
    "    out_path = os.path.join(out_dir, fname)\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5ba2194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In simple words bind tools restrict agents from calling any tool they want. tools_node has access to both tools and its python function or tool executor.\n",
    "\n",
    "# Helpful Analogy:\n",
    "   # Shop shelves = ToolNode → has both eggs and bread available (all tools that can be executed).\n",
    "   # Person A = Researcher Agent (bind_tools([bread])) → is only told about bread.\n",
    "   # Person B = Visualizer Agent (bind_tools([eggs])) → is only told about eggs.\n",
    "        # If Person A (Researcher) tries to ask for eggs (plot_table), the model won't even think about eggs most of the time — because it doesn't know that eggs exist.\n",
    "        # If, somehow, Person A misbehaves and asks for eggs anyway (rare, but LLMs can hallucinate), the ToolNode still has eggs and would hand them over (because it's stocked with everything).\n",
    "\n",
    "\n",
    "# We need both binding and ToolNode.\n",
    "# Bind_tools tells the model (LLM runnable) what tools it is allowed to call and what their argument \n",
    "# schema looks like. It’s a model-side permission and spec.\n",
    "\n",
    "## Clarification: LangChain automatically injects those tool specs into the system prompt / OpenAI function-calling schema.\n",
    "        ## The LLM now knows:\n",
    "                ## Tool names\n",
    "                ## Input parameters & types\n",
    "                ## Tool descriptions (from decorators / docstrings)\n",
    "\n",
    "## Researcher should only be able to call web_search\n",
    "researcher_llm = llm.bind_tools([web_search])\n",
    "## Visualizer should only be able to call plot_table\n",
    "visualizer_llm = llm.bind_tools([plot_table])\n",
    "\n",
    "# ToolNode (or your custom tool-executor) actually runs the Python function when the model emits a tool \n",
    "# call. It’s a runtime executor.\n",
    "## ToolNode knows how to run either tool when asked\n",
    "tools_node = ToolNode([web_search, plot_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0d57bd",
   "metadata": {},
   "source": [
    "### **```Prompts per agent```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "491e8adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts per agent\n",
    "\n",
    "planner_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are the Planner. Read the user request and produce a short plan (2–6 numbered steps). Indicate missing information as 1–3 direct questions. Do NOT call tools. Keep each step ≤ 20 words.\"),\n",
    "    MessagesPlaceholder(\"messages\"),\n",
    "])\n",
    "\n",
    "researcher_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are the Researcher. Gather reliable facts and short evidence fragments, then synthesize. \"\n",
    "     \"If external info is needed, call tool web_search with an argument like {{\\\"user_input\\\": \\\"EV adoption Pakistan 2023 statistics\\\"}}. \"\n",
    "     \"After any tool use, include up to 3 quoted evidence snippets (≤25 words each) with a 1-line source label, then a 2–4 sentence synthesis with provenance when possible. Keep output ≤220 words.\"),\n",
    "    MessagesPlaceholder(\"messages\"),\n",
    "])\n",
    "\n",
    "summarizer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are the Summarizer. Produce 4–6 bullet points. Each bullet should start with a bold one-line header (e.g., **Key finding:**) followed by 1–2 sentences. Add one action-item bullet at the end (who does what next). Keep total ≤180 words.\"),\n",
    "    MessagesPlaceholder(\"messages\"),\n",
    "])\n",
    "\n",
    "visualizer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are the Visualizer. If table_text is present or a table exists in the messages, propose a chart spec (title, x_col, y_col, chart_type). \"\n",
    "     \"Then either call the tool plot_table with arguments like {{\\\"table_text\\\": \\\"<CSV or markdown table>\\\", \\\"chart_type\\\": \\\"line\\\"}} to draw it, \"\n",
    "     \"OR return a JSON spec in the exact format {{\\\"action\\\":\\\"spec_only\\\",\\\"chart_type\\\":\\\"line\\\",\\\"title\\\":\\\"EV adoption\\\",\\\"x_col\\\":\\\"year\\\",\\\"y_col\\\":\\\"ev_count\\\",\\\"notes\\\":\\\"...\\\"}}. \"\n",
    "     \"If you call plot_table, include a 1-line rationale for the choice. Keep text concise.\"),\n",
    "    MessagesPlaceholder(\"messages\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c0b6f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runnables\n",
    "## Passing prompts to LLM to create runnables\n",
    "## Docstrings/descriptions of bound tools directly shape the LLM’s reasoning about what it can call.\n",
    "\n",
    "planner_runnable    = planner_prompt    | llm\n",
    "researcher_runnable = researcher_prompt | researcher_llm\n",
    "summarizer_runnable = summarizer_prompt | llm\n",
    "visualizer_runnable = visualizer_prompt | visualizer_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a1ccdc",
   "metadata": {},
   "source": [
    "### **``Define nodes``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c4f9b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node implementations\n",
    "## Function that will be triggered in each node.\n",
    "\n",
    "## Clarification: Regarding whether we need to put docstrings like we do when we bind tools with llms or not and to answer that question ->\n",
    "    ## Those are graph nodes (Python callables) inside LangGraph. They are not exposed as tools to the LLM.\n",
    "    ## Instead, you wrap them in prompts (ChatPromptTemplate) where you provide the system message like:\n",
    "\n",
    "def planner_agent(state: MyGraphState):\n",
    "    ai = planner_runnable.invoke(state)\n",
    "    return {\"messages\": [ai]}\n",
    "\n",
    "def researcher_agent(state: MyGraphState):\n",
    "    ai = researcher_runnable.invoke(state)\n",
    "    return {\"messages\": [ai]}\n",
    "\n",
    "def summarizer_agent(state: MyGraphState):\n",
    "    ai = summarizer_runnable.invoke(state)\n",
    "    return {\"messages\": [ai]}\n",
    "\n",
    "def visualizer_agent(state: MyGraphState):\n",
    "    \"\"\"\n",
    "    Run the visualizer LLM. If it emits a tool call, we return the AIMessage\n",
    "    and let the ToolNode run the tool in the next graph step. If it emits no\n",
    "    tool call but table_text exists, auto-invoke plot_table here.\n",
    "    \"\"\"\n",
    "    ai = visualizer_runnable.invoke(state)\n",
    "    # If the model already requested a tool, return only the AIMessage.\n",
    "    # The graph's conditional routing should send us to the ToolNode next.\n",
    "    tool_calls = getattr(ai, \"tool_calls\", None)\n",
    "    if tool_calls and len(tool_calls) > 0:\n",
    "        # Do NOT auto-run the tool here — ToolNode will run it next.\n",
    "        return {\"messages\": [ai]}\n",
    "\n",
    "    # No tool call present. If table_text exists, auto-plot.\n",
    "    out_messages = [ai]\n",
    "    if state.get(\"table_text\"):\n",
    "        try:\n",
    "            chart_type = \"line\"\n",
    "            content_lower = (ai.content or \"\").lower()\n",
    "            if \"bar chart\" in content_lower or (\"bar\" in content_lower and \"line\" not in content_lower):\n",
    "                chart_type = \"bar\"\n",
    "            elif \"scatter\" in content_lower:\n",
    "                chart_type = \"scatter\"\n",
    "\n",
    "            file_path = plot_table.invoke(state[\"table_text\"], chart_type)\n",
    "            # Return a ToolMessage so downstream consumers see the tool result\n",
    "            tm = ToolMessage(tool_call_id=str(uuid4()), name=\"plot_table\", content=file_path)\n",
    "            out_messages.append(tm)\n",
    "\n",
    "            # Optionally add a follow-up AIMessage (safe since there was no tool_use)\n",
    "            follow_up = AIMessage(content=f\"Automatically plotted table as a {chart_type} chart. File saved at: {file_path}\")\n",
    "            out_messages.append(follow_up)\n",
    "        except Exception as e:\n",
    "            out_messages.append(AIMessage(content=f\"Failed to auto-plot the table: {e}\"))\n",
    "\n",
    "    return {\"messages\": out_messages}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c4fa3d",
   "metadata": {},
   "source": [
    "### **``Edge conditions``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3f683050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Router logic (mode-driven) OR Edge conditions\n",
    "\n",
    "def route_from_researcher(state: MyGraphState):\n",
    "    mode = state.get(\"mode\", \"full\")\n",
    "    last = state[\"messages\"][-1]\n",
    "    if hasattr(last, \"tool_calls\") and last.tool_calls:\n",
    "        return \"tools\"\n",
    "    if mode == \"research\":\n",
    "        return END\n",
    "    return \"summarizer_agent\"\n",
    "\n",
    "def route_from_summarizer(state: MyGraphState):\n",
    "    mode = state.get(\"mode\", \"full\")\n",
    "    last = state[\"messages\"][-1]\n",
    "    if hasattr(last, \"tool_calls\") and last.tool_calls:\n",
    "        return \"tools\"\n",
    "    if mode == \"summary\":\n",
    "        return END\n",
    "    return \"visualizer_agent\"\n",
    "\n",
    "def route_from_visualizer(state: MyGraphState):\n",
    "    last = state[\"messages\"][-1]\n",
    "    if hasattr(last, \"tool_calls\") and last.tool_calls:\n",
    "        return \"tools\"\n",
    "    # if mode is visualize, stop after visualizer; else continue to END\n",
    "    mode = state.get(\"mode\", \"full\")\n",
    "    if mode == \"visualize\":\n",
    "        return END\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad59ea0c",
   "metadata": {},
   "source": [
    "### **``Create a graph instance of StateGraph``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f7d9cebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of StateGraph with the structure of MyGraphState\n",
    "workflow = StateGraph(MyGraphState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf5fa30",
   "metadata": {},
   "source": [
    "### **``Add nodes to Graph``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bf89cfab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x24529825040>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "workflow.add_node(\"planner_agent\",    planner_agent)   \n",
    "workflow.add_node(\"researcher_agent\", researcher_agent)\n",
    "workflow.add_node(\"summarizer_agent\", summarizer_agent)\n",
    "workflow.add_node(\"visualizer_agent\", visualizer_agent)\n",
    "workflow.add_node(\"tools\",            tools_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdb24c9",
   "metadata": {},
   "source": [
    "### **``Add edges to the graph``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f4eb2b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x24529825040>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the nodes one after another. \n",
    "# All the Nodes in the workflow take state as input, update the state and pass it to the next Node as input.\n",
    "# Output of Node1 goes to Node2 as input. Output of Node2 goes to Node3 as input.\n",
    "workflow.add_edge(START, \"planner_agent\")\n",
    "workflow.add_edge(\"planner_agent\", \"researcher_agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\"researcher_agent\", route_from_researcher,\n",
    "                               {\"tools\": \"tools\", \"summarizer_agent\": \"summarizer_agent\", str(END): str(END)})\n",
    "\n",
    "# tools -> back to researcher (research loop)\n",
    "workflow.add_edge(\"tools\", \"researcher_agent\")\n",
    "\n",
    "\n",
    "# Information regarding how conditional edges work:\n",
    "## workflow.add_conditional_edges(from_node, condition_fn, mapping)\n",
    "    # This means:\n",
    "    # When the graph finishes running from_node, call condition_fn(state). Based on its return value, go to the mapped next node.\n",
    "workflow.add_conditional_edges(\"summarizer_agent\", route_from_summarizer,\n",
    "                               {\"visualizer_agent\": \"visualizer_agent\", str(END): str(END)})\n",
    "\n",
    "# allow visualizer to call tools and loop back to itself\n",
    "workflow.add_conditional_edges(\"visualizer_agent\", route_from_visualizer,\n",
    "                               {\"tools\": \"tools\", str(END): str(END)})\n",
    "workflow.add_edge(\"tools\", \"visualizer_agent\")\n",
    "\n",
    "workflow.add_edge(\"visualizer_agent\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfac7835",
   "metadata": {},
   "source": [
    "### **``Compile the graph``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a386fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the workflow\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ec9a5149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers Functions\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolMessage, HumanMessage\n",
    "\n",
    "def _flatten_messages(raw_messages):\n",
    "    \"\"\"Yield message objects in a flat sequence from possibly nested lists.\"\"\"\n",
    "    stack = list(raw_messages)\n",
    "    while stack:\n",
    "        m = stack.pop(0)\n",
    "        if m is None:\n",
    "            continue\n",
    "        if isinstance(m, (list, tuple)):\n",
    "            stack = list(m) + stack\n",
    "            continue\n",
    "        yield m\n",
    "\n",
    "def last_nonempty_ai_message(messages):\n",
    "    \"\"\"\n",
    "    Find last AIMessage with non-empty textual content.\n",
    "    Handles nested lists and ToolMessage content that might be non-string.\n",
    "    \"\"\"\n",
    "    last_found = None\n",
    "    for m in _flatten_messages(messages):\n",
    "        # Debugging: print unexpected types (optional)\n",
    "        if not isinstance(m, (AIMessage, ToolMessage, HumanMessage)):\n",
    "            # You can log this instead of printing in production\n",
    "            # print(\"DEBUG: unexpected message type:\", type(m), m)\n",
    "            pass\n",
    "\n",
    "        if isinstance(m, AIMessage):\n",
    "            content = m.content or \"\"\n",
    "            if isinstance(content, (list, tuple)):\n",
    "                # flatten if AIMessage.content is a list of strings\n",
    "                text = \" \".join(str(x) for x in content if x)\n",
    "            else:\n",
    "                text = str(content)\n",
    "            if text.strip():\n",
    "                last_found = m\n",
    "\n",
    "        # Sometimes tools return their result as ToolMessage.content (string or other)\n",
    "        # but we only want AIMessage textual syntheses here.\n",
    "\n",
    "    return last_found\n",
    "\n",
    "\n",
    "def try_draw_graph(app):\n",
    "    try:\n",
    "        png = app.get_graph().draw_mermaid_png()\n",
    "        from IPython.display import Image, display\n",
    "        display(Image(png))\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609af51a",
   "metadata": {},
   "source": [
    "### **``Visualize the graph``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "611be940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize your graph\n",
    "from IPython.display import Image, display\n",
    "png = app.get_graph().draw_mermaid_png()\n",
    "\n",
    "display(Image(png))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bdb45e",
   "metadata": {},
   "source": [
    "### **``Test your graph``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1a5eb19c",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages.3: `tool_use` ids were found without `tool_result` blocks immediately after: toolu_01Ep7TBQQyVwAwE8NXdXdrVj. Each `tool_use` block must have a corresponding `tool_result` block in the next message.'}, 'request_id': 'req_011CTfZifeSTbDcQykKN36tu'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Example 1: research-only\u001b[39;00m\n\u001b[32m     14\u001b[39m inputs = {\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mFind 2 recent stats on EV adoption in Pakistan and summarize.\u001b[39m\u001b[33m\"\u001b[39m)],\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mresearch\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m out = \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Research-only final ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m final = last_nonempty_ai_message(out[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\My Projects\\Hegtavic Projects\\Wand_ai\\Multi-agent-task-solver\\backend\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3026\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3023\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3024\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3026\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3027\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3028\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3029\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3030\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3031\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3032\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3033\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3034\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3035\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3036\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3037\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3038\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3039\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3040\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3041\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\My Projects\\Hegtavic Projects\\Wand_ai\\Multi-agent-task-solver\\backend\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2647\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2645\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2646\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2647\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2654\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2657\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\My Projects\\Hegtavic Projects\\Wand_ai\\Multi-agent-task-solver\\backend\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:253\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m.\u001b[49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpanic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    258\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tb := exc.__traceback__:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\My Projects\\Hegtavic Projects\\Wand_ai\\Multi-agent-task-solver\\backend\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:511\u001b[39m, in \u001b[36m_panic_or_proceed\u001b[39m\u001b[34m(futs, timeout_exc_cls, panic)\u001b[39m\n\u001b[32m    509\u001b[39m                 interrupts.append(exc)\n\u001b[32m    510\u001b[39m             \u001b[38;5;28;01melif\u001b[39;00m fut \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SKIP_RERAISE_SET:\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    512\u001b[39m \u001b[38;5;66;03m# raise combined interrupts\u001b[39;00m\n\u001b[32m    513\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m interrupts:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\My Projects\\Hegtavic Projects\\Wand_ai\\Multi-agent-task-solver\\backend\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_executor.py:81\u001b[39m, in \u001b[36mBackgroundExecutor.done\u001b[39m\u001b[34m(self, task)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Remove the task from the tasks dict when it's done.\"\"\"\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m GraphBubbleUp:\n\u001b[32m     83\u001b[39m     \u001b[38;5;66;03m# This exception is an interruption signal, not an error\u001b[39;00m\n\u001b[32m     84\u001b[39m     \u001b[38;5;66;03m# so we don't want to re-raise it on exit\u001b[39;00m\n\u001b[32m     85\u001b[39m     \u001b[38;5;28mself\u001b[39m.tasks.pop(task)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.10-windows-x86_64-none\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.10-windows-x86_64-none\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.10-windows-x86_64-none\\Lib\\concurrent\\futures\\thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\My Projects\\Hegtavic Projects\\Wand_ai\\Multi-agent-task-solver\\backend\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\My Projects\\Hegtavic Projects\\Wand_ai\\Multi-agent-task-solver\\backend\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:657\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\My Projects\\Hegtavic Projects\\Wand_ai\\Multi-agent-task-solver\\backend\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:401\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    399\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mvisualizer_agent\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvisualizer_agent\u001b[39m(state: MyGraphState):\n\u001b[32m     21\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[33;03m    Run the visualizer LLM. If it emits a tool call, we return the AIMessage\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[33;03m    and let the ToolNode run the tool in the next graph step. If it emits no\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03m    tool call but table_text exists, auto-invoke plot_table here.\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     ai = \u001b[43mvisualizer_runnable\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     \u001b[38;5;66;03m# If the model already requested a tool, return only the AIMessage.\u001b[39;00m\n\u001b[32m     28\u001b[39m     \u001b[38;5;66;03m# The graph's conditional routing should send us to the ToolNode next.\u001b[39;00m\n\u001b[32m     29\u001b[39m     tool_calls = \u001b[38;5;28mgetattr\u001b[39m(ai, \u001b[33m\"\u001b[39m\u001b[33mtool_calls\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\My Projects\\Hegtavic Projects\\Wand_ai\\Multi-agent-task-solver\\backend\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3245\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3243\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3244\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3245\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3246\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3247\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\My Projects\\Hegtavic Projects\\Wand_ai\\Multi-agent-task-solver\\backend\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5710\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5703\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5704\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5705\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5708\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5709\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5710\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5711\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5712\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5713\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5714\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\My Projects\\Hegtavic Projects\\Wand_ai\\Multi-agent-task-solver\\backend\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:395\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m     **kwargs: Any,\n\u001b[32m    391\u001b[39m ) -> BaseMessage:\n\u001b[32m    392\u001b[39m     config = ensure_config(config)\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    394\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    405\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\My Projects\\Hegtavic Projects\\Wand_ai\\Multi-agent-task-solver\\backend\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1023\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1014\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1020\u001b[39m     **kwargs: Any,\n\u001b[32m   1021\u001b[39m ) -> LLMResult:\n\u001b[32m   1022\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\My Projects\\Hegtavic Projects\\Wand_ai\\Multi-agent-task-solver\\backend\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:840\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    838\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    839\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m840\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    846\u001b[39m         )\n\u001b[32m    847\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    848\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\My Projects\\Hegtavic Projects\\Wand_ai\\Multi-agent-task-solver\\backend\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1089\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1087\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1088\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1089\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1093\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\My Projects\\Hegtavic Projects\\Wand_ai\\Multi-agent-task-solver\\backend\\.venv\\Lib\\site-packages\\langchain_anthropic\\chat_models.py:1762\u001b[39m, in \u001b[36mChatAnthropic._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1760\u001b[39m     data = \u001b[38;5;28mself\u001b[39m._create(payload)\n\u001b[32m   1761\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m anthropic.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43m_handle_anthropic_bad_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._format_output(data, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\My Projects\\Hegtavic Projects\\Wand_ai\\Multi-agent-task-solver\\backend\\.venv\\Lib\\site-packages\\langchain_anthropic\\chat_models.py:1760\u001b[39m, in \u001b[36mChatAnthropic._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1758\u001b[39m payload = \u001b[38;5;28mself\u001b[39m._get_request_payload(messages, stop=stop, **kwargs)\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1760\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1761\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m anthropic.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1762\u001b[39m     _handle_anthropic_bad_request(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\My Projects\\Hegtavic Projects\\Wand_ai\\Multi-agent-task-solver\\backend\\.venv\\Lib\\site-packages\\langchain_anthropic\\chat_models.py:1619\u001b[39m, in \u001b[36mChatAnthropic._create\u001b[39m\u001b[34m(self, payload)\u001b[39m\n\u001b[32m   1617\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m payload:\n\u001b[32m   1618\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.beta.messages.create(**payload)\n\u001b[32m-> \u001b[39m\u001b[32m1619\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\My Projects\\Hegtavic Projects\\Wand_ai\\Multi-agent-task-solver\\backend\\.venv\\Lib\\site-packages\\anthropic\\_utils\\_utils.py:282\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    280\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\My Projects\\Hegtavic Projects\\Wand_ai\\Multi-agent-task-solver\\backend\\.venv\\Lib\\site-packages\\anthropic\\resources\\messages\\messages.py:930\u001b[39m, in \u001b[36mMessages.create\u001b[39m\u001b[34m(self, max_tokens, messages, model, metadata, service_tier, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[32m    924\u001b[39m     warnings.warn(\n\u001b[32m    925\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    926\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m    927\u001b[39m         stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    928\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/v1/messages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop_sequences\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthinking\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsStreaming\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\My Projects\\Hegtavic Projects\\Wand_ai\\Multi-agent-task-solver\\backend\\.venv\\Lib\\site-packages\\anthropic\\_base_client.py:1324\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1310\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1311\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1312\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1319\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1320\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1321\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1322\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1323\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\My Projects\\Hegtavic Projects\\Wand_ai\\Multi-agent-task-solver\\backend\\.venv\\Lib\\site-packages\\anthropic\\_base_client.py:1112\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1109\u001b[39m             err.response.read()\n\u001b[32m   1111\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1112\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1114\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1116\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages.3: `tool_use` ids were found without `tool_result` blocks immediately after: toolu_01Ep7TBQQyVwAwE8NXdXdrVj. Each `tool_use` block must have a corresponding `tool_result` block in the next message.'}, 'request_id': 'req_011CTfZifeSTbDcQykKN36tu'}",
      "During task with name 'visualizer_agent' and id 'bfbb907a-2d05-5cc2-b420-f364f62afc6a'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "# ---------------------------\n",
    "# Example runs\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Quick env check\n",
    "    if not os.environ.get(\"TAVILY_API_KEY\"):\n",
    "        print(\"WARNING: TAVILY_API_KEY missing in environment (set it to run web_search).\")\n",
    "\n",
    "    # Example 1: research-only\n",
    "    inputs = {\n",
    "        \"messages\": [HumanMessage(content=\"Find 2 recent stats on EV adoption in Pakistan and summarize.\")],\n",
    "        \"mode\": \"research\"\n",
    "    }\n",
    "    out = app.invoke(inputs)\n",
    "    print(\"\\n--- Research-only final ---\")\n",
    "    final = last_nonempty_ai_message(out[\"messages\"])\n",
    "    print(final.content if final else \"(no non-empty AI message)\")\n",
    "\n",
    "    time.sleep(2)  # <-- delay between runs\n",
    "\n",
    "    # Example 2: summary-only\n",
    "    inputs2 = {\n",
    "        \"messages\": [HumanMessage(content=\"Find 2 recent stats on EV adoption in Pakistan and summarize.\")],\n",
    "        \"mode\": \"summary\"\n",
    "    }\n",
    "    out2 = app.invoke(inputs2)\n",
    "    print(\"\\n--- Summary-only final ---\")\n",
    "    final2 = last_nonempty_ai_message(out2[\"messages\"])\n",
    "    print(final2.content if final2 else \"(no non-empty AI message)\")\n",
    "\n",
    "    time.sleep(2)  # <-- delay between runs\n",
    "\n",
    "    # Example 3: visualize with CSV provided\n",
    "    csv_text = \"year,ev_count\\n2018,1000\\n2019,3000\\n2020,7000\\n2021,15000\\n2022,23000\\n\"\n",
    "    inputs3 = {\n",
    "        \"messages\": [HumanMessage(content=\"Please visualize the table below.\\n\\n\" + csv_text)],\n",
    "        \"mode\": \"visualize\",\n",
    "        \"table_text\": csv_text\n",
    "    }\n",
    "    out3 = app.invoke(inputs3)\n",
    "    print(\"\\n--- Visualize final ---\")\n",
    "    final3 = last_nonempty_ai_message(out3[\"messages\"])\n",
    "    print(final3.content if final3 else \"(no non-empty AI message)\")\n",
    "\n",
    "    # Look for produced ToolMessage(s) with plot output\n",
    "    for m in out3[\"messages\"]:\n",
    "        if isinstance(m, ToolMessage) and getattr(m, \"name\", \"\") == \"plot_table\":\n",
    "            print(\"Plot produced at:\", getattr(m, \"content\", None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a64fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc351a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
